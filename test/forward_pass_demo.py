# -*- coding: utf-8 -*-
"""
å®é™…æ¨¡å‹å‰å‘ä¼ æ’­æ¼”ç¤ºè„šæœ¬
é€šè¿‡å…·ä½“ä»£ç å’Œæ•°æ®æ¼”ç¤ºæ¨¡å‹çš„å®Œæ•´å·¥ä½œæµç¨‹
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from torch_geometric.data import Data

def create_mock_models():
    """
    åˆ›å»ºç®€åŒ–ç‰ˆçš„æ¨¡å‹ç»„ä»¶ç”¨äºæ¼”ç¤º
    """
    class MockSharedEncoder(nn.Module):
        def __init__(self, in_channels=305, hidden_channels=512):
            super().__init__()
            self.conv1 = nn.Linear(in_channels, hidden_channels)  # ç®€åŒ–çš„"GraphSAGE"
            self.conv2 = nn.Linear(hidden_channels, hidden_channels)
            self.mlp = nn.Sequential(
                nn.Linear(hidden_channels, hidden_channels),
                nn.ReLU(),
                nn.Linear(hidden_channels, hidden_channels)
            )
        
        def forward(self, x, edge_index):
            print(f"    ğŸ“¥ SharedEncoderè¾“å…¥: x.shape={x.shape}")
            
            x_1 = F.relu(self.conv1(x))
            print(f"    ğŸ”„ ç¬¬1å±‚GraphSAGE: {x_1.shape}")
            
            x_2 = F.relu(self.conv2(x_1))
            print(f"    ğŸ”„ ç¬¬2å±‚GraphSAGE: {x_2.shape}")
            
            x_out = x_1 + self.mlp(x_2)  # è·³è·ƒè¿æ¥
            print(f"    ğŸ“¤ SharedEncoderè¾“å‡º: {x_out.shape}")
            return x_out
    
    class MockCascadePredictor(nn.Module):
        def __init__(self, shared_encoder, hidden_channels=512):
            super().__init__()
            self.shared_encoder = shared_encoder
            self.attention = nn.MultiheadAttention(hidden_channels, 4, batch_first=True)
        
        def forward(self, x, edge_index, pred_edge_index):
            print(f"\n  ğŸ”® CascadePredictorå·¥ä½œæµç¨‹:")
            print(f"    ğŸ“¥ è¾“å…¥è¾¹ç´¢å¼•: {pred_edge_index}")
            
            # ç¼–ç èŠ‚ç‚¹
            z = self.shared_encoder(x, edge_index)
            
            # è§£ç é“¾æ¥
            src, dst = pred_edge_index
            z_src = z[src].unsqueeze(1)
            z_dst = z[dst].unsqueeze(1)
            print(f"    ğŸ”— æºèŠ‚ç‚¹åµŒå…¥: {z_src.shape}")
            print(f"    ğŸ”— ç›®æ ‡èŠ‚ç‚¹åµŒå…¥: {z_dst.shape}")
            
            z_combined = torch.cat([z_src, z_dst], dim=1)
            print(f"    ğŸ¤ ç»„åˆåµŒå…¥: {z_combined.shape}")
            
            attn_output, attn_weights = self.attention(z_combined, z_combined, z_combined)
            print(f"    ğŸ§  æ³¨æ„åŠ›è¾“å‡º: {attn_output.shape}")
            
            link_probs = torch.sigmoid(attn_output[:, 0, :].sum(dim=-1))
            print(f"    ğŸ“Š é“¾æ¥æ¦‚ç‡: {link_probs}")
            return link_probs
    
    class MockRumorDetector(nn.Module):
        def __init__(self, shared_encoder, hidden_channels=512, out_channels=4):
            super().__init__()
            self.shared_encoder = shared_encoder
            self.fc = nn.Linear(hidden_channels, out_channels)
        
        def forward(self, x, edge_index, batch):
            print(f"\n  ğŸ•µï¸ RumorDetectorå·¥ä½œæµç¨‹:")
            
            # ä½¿ç”¨å…±äº«ç¼–ç å™¨
            z = self.shared_encoder(x, edge_index)
            
            # ç®€åŒ–çš„æ± åŒ–ï¼ˆå®é™…æ˜¯SAGPooling + global_mean_poolï¼‰
            pooled = z.mean(dim=0, keepdim=True)  # ç®€åŒ–ä¸ºå…¨å±€å¹³å‡
            print(f"    ğŸŠ æ± åŒ–å: {pooled.shape}")
            
            # åˆ†ç±»
            logits = self.fc(pooled)
            probs = F.log_softmax(logits, dim=-1)
            print(f"    ğŸ“ˆ åˆ†ç±»æ¦‚ç‡: {probs}")
            return probs
    
    class MockEndToEndModel(nn.Module):
        def __init__(self, shared_encoder, cascade_predictor, rumor_detector):
            super().__init__()
            self.shared_encoder = shared_encoder
            self.cascade_predictor = cascade_predictor
            self.rumor_detector = rumor_detector
        
        def forward(self, data):
            print(f"\nğŸš€ EndToEndModelå‰å‘ä¼ æ’­:")
            print(f"  ğŸ“¥ è¾“å…¥æ•°æ®: x={data.x.shape}, edge_index={data.edge_index.shape}")
            
            # æ­¥éª¤1: é“¾æ¥é¢„æµ‹
            print(f"\n  === æ­¥éª¤1: é“¾æ¥é¢„æµ‹ ===")
            pred_edges = self.cascade_predictor(data.x, data.edge_index, data.pred_edge_index)
            
            # æ­¥éª¤2: å›¾é‡æ„
            print(f"\n  === æ­¥éª¤2: å›¾é‡æ„ ===")
            significant_edges = data.pred_edge_index[:, pred_edges > 0.5]
            print(f"    ğŸ” é¢„æµ‹æ¦‚ç‡>0.5çš„è¾¹: {significant_edges.shape[1]}æ¡")
            
            reconstructed_edge_index = torch.cat([data.edge_index, significant_edges], dim=1)
            print(f"    ğŸ—ï¸ é‡æ„å›¾è¾¹æ•°: åŸå§‹{data.edge_index.shape[1]} + é¢„æµ‹{significant_edges.shape[1]} = {reconstructed_edge_index.shape[1]}")
            
            # æ­¥éª¤3: è°£è¨€æ£€æµ‹  
            print(f"\n  === æ­¥éª¤3: è°£è¨€æ£€æµ‹ ===")
            rumor_output = self.rumor_detector(data.x, reconstructed_edge_index, None)
            
            return rumor_output, pred_edges
    
    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    shared_encoder = MockSharedEncoder()
    cascade_predictor = MockCascadePredictor(shared_encoder)
    rumor_detector = MockRumorDetector(shared_encoder)
    end_to_end_model = MockEndToEndModel(shared_encoder, cascade_predictor, rumor_detector)
    
    return end_to_end_model, shared_encoder, cascade_predictor, rumor_detector

def create_sample_data():
    """
    åˆ›å»ºç¤ºä¾‹æ•°æ®
    """
    print("ğŸ“Š åˆ›å»ºç¤ºä¾‹ä¼ æ’­æ•°æ®:")
    print("  ä¼ æ’­åœºæ™¯: æ¨æ–‡Aâ†’æ¨æ–‡Bâ†’æ¨æ–‡C, æ¨æ–‡Aâ†’æ¨æ–‡Dâ†’æ¨æ–‡E")
    print("  æ—¶åºåˆ†å‰²: å‰75%ä¸ºæ—©æœŸå›¾ï¼Œå25%ä¸ºé¢„æµ‹ç›®æ ‡")
    
    # èŠ‚ç‚¹ç‰¹å¾ (5ä¸ªèŠ‚ç‚¹, 305ç»´ç‰¹å¾)
    num_nodes = 5
    x = torch.randn(num_nodes, 305)  # Word2Vec(300) + åº¦æ•°ç‰¹å¾(5)
    
    # æ—©æœŸè§‚å¯Ÿåˆ°çš„è¾¹ (å‰75%æ—¶é—´)
    edge_index = torch.tensor([
        [0, 0, 1],  # æºèŠ‚ç‚¹: A, A, B  
        [1, 3, 2]   # ç›®æ ‡èŠ‚ç‚¹: B, D, C
    ], dtype=torch.long)  # Aâ†’B, Aâ†’D, Bâ†’C
    
    # å¾…é¢„æµ‹çš„è¾¹ (å25%æ—¶é—´)
    pred_edge_index = torch.tensor([
        [3],  # æºèŠ‚ç‚¹: D
        [4]   # ç›®æ ‡èŠ‚ç‚¹: E  
    ], dtype=torch.long)  # Dâ†’E
    
    # è°£è¨€æ ‡ç­¾ (0:false, 1:true, 2:unverified, 3:non-rumor)
    label = torch.tensor([1], dtype=torch.long)  # å‡è®¾è¿™æ˜¯çœŸè°£è¨€
    
    # åˆ›å»ºPyGæ•°æ®å¯¹è±¡
    data = Data(
        x=x,
        edge_index=edge_index,
        pred_edge_index=pred_edge_index,
        label=label
    )
    
    print(f"  âœ… èŠ‚ç‚¹ç‰¹å¾: {x.shape}")
    print(f"  âœ… æ—©æœŸè¾¹: {edge_index.shape} {edge_index.tolist()}")
    print(f"  âœ… é¢„æµ‹è¾¹: {pred_edge_index.shape} {pred_edge_index.tolist()}")
    print(f"  âœ… æ ‡ç­¾: {label.item()} (1=çœŸè°£è¨€)")
    
    return data

def demonstrate_forward_pass():
    """
    æ¼”ç¤ºå®Œæ•´çš„å‰å‘ä¼ æ’­è¿‡ç¨‹
    """
    print("=" * 80)
    print("ğŸ­ D2æ¨¡å‹å‰å‘ä¼ æ’­æ¼”ç¤º")
    print("=" * 80)
    
    # åˆ›å»ºæ•°æ®å’Œæ¨¡å‹
    data = create_sample_data()
    model, shared_encoder, cascade_predictor, rumor_detector = create_mock_models()
    
    print(f"\nğŸƒ å¼€å§‹å‰å‘ä¼ æ’­...")
    
    # æ‰§è¡Œå‰å‘ä¼ æ’­
    with torch.no_grad():
        rumor_output, pred_edges = model(data)
    
    # è§£é‡Šç»“æœ
    print(f"\nğŸ“‹ æœ€ç»ˆç»“æœ:")
    print(f"  ğŸ”— é“¾æ¥é¢„æµ‹æ¦‚ç‡: {pred_edges.numpy():.4f}")
    print(f"      â†’ æ¦‚ç‡>0.5: {'æ˜¯' if pred_edges.item() > 0.5 else 'å¦'}")
    print(f"      â†’ è§£é‡Š: Dâ†’Eè¿™æ¡è¾¹{'å¾ˆå¯èƒ½' if pred_edges.item() > 0.5 else 'ä¸å¤ªå¯èƒ½'}åœ¨æœªæ¥å‡ºç°")
    
    print(f"  ğŸ•µï¸ è°£è¨€åˆ†ç±»æ¦‚ç‡: {rumor_output.numpy()}")
    predicted_class = rumor_output.argmax().item()
    class_names = ['å‡è°£è¨€', 'çœŸè°£è¨€', 'æœªéªŒè¯', 'éè°£è¨€']
    print(f"      â†’ é¢„æµ‹ç±»åˆ«: {predicted_class} ({class_names[predicted_class]})")
    print(f"      â†’ çœŸå®ç±»åˆ«: {data.label.item()} ({class_names[data.label.item()]})")

def explain_shared_encoder_role():
    """
    è¯¦ç»†è§£é‡ŠSharedEncoderçš„ä½œç”¨æœºåˆ¶
    """
    print(f"\nğŸ§  SharedEncoderä½œç”¨æœºåˆ¶è¯¦è§£:")
    print("=" * 50)
    
    print("""
    ğŸ¯ ä¸ºä»€ä¹ˆSharedEncoderæ˜¯è”åˆè®­ç»ƒçš„å…³é”®ï¼Ÿ
    
    1. å‚æ•°å…±äº«æœºåˆ¶:
       â€¢ CascadePredictorå’ŒRumorDetectoréƒ½ä½¿ç”¨åŒä¸€ä¸ªSharedEncoder
       â€¢ å½“CascadePredictoræ›´æ–°æ—¶ï¼ŒSharedEncoderå‚æ•°æ”¹å˜
       â€¢ è¿™ä¸ªæ”¹å˜ä¼šç›´æ¥å½±å“RumorDetectorçš„æ€§èƒ½
       â€¢ åä¹‹äº¦ç„¶ï¼Œå½¢æˆç›¸äº’å½±å“çš„é—­ç¯
    
    2. æ¢¯åº¦ä¼ æ’­è·¯å¾„:
       æŸå¤±1 (é“¾æ¥é¢„æµ‹) â†’ CascadePredictor â†’ SharedEncoder â† RumorDetector â† æŸå¤±2 (è°£è¨€æ£€æµ‹)
                                              â†‘
                                         å‚æ•°åŒæ—¶æ¥æ”¶ä¸¤ä¸ªæ¢¯åº¦
    
    3. ç‰¹å¾ç©ºé—´ç»Ÿä¸€:
       â€¢ ä¸¤ä¸ªä»»åŠ¡åœ¨ç›¸åŒçš„512ç»´åµŒå…¥ç©ºé—´ä¸­å·¥ä½œ
       â€¢ é“¾æ¥é¢„æµ‹å­¦åˆ°çš„"ä¼ æ’­æ¨¡å¼"ç‰¹å¾
       â€¢ è°£è¨€æ£€æµ‹å­¦åˆ°çš„"è¯­ä¹‰å†…å®¹"ç‰¹å¾
       â€¢ åœ¨SharedEncoderä¸­èåˆæˆ"ä¼ æ’­-è¯­ä¹‰"è”åˆç‰¹å¾
    
    4. ä¿¡æ¯äº’ä¼ æœºåˆ¶:
       CascadePredictor â†’ SharedEncoder â†’ RumorDetector:
       "è¿™ä¸ªä¼ æ’­æ¨¡å¼å¾ˆåƒè°£è¨€çš„çˆ†å‘å¼ä¼ æ’­"
       
       RumorDetector â†’ SharedEncoder â†’ CascadePredictor:  
       "è¿™ä¸ªå†…å®¹æ˜¯è°£è¨€ï¼Œä¼ æ’­åº”è¯¥æ›´éšæœºå’Œå¹¿æ³›"
    """)

def demonstrate_training_step():
    """
    æ¼”ç¤ºä¸€ä¸ªè®­ç»ƒæ­¥éª¤
    """
    print(f"\nğŸ‹ï¸ è”åˆè®­ç»ƒæ­¥éª¤æ¼”ç¤º:")
    print("=" * 50)
    
    # åˆ›å»ºæ•°æ®å’Œæ¨¡å‹
    data = create_sample_data()
    model, shared_encoder, cascade_predictor, rumor_detector = create_mock_models()
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    
    print("ğŸ“ è®­ç»ƒæ­¥éª¤:")
    print("  1. å‰å‘ä¼ æ’­")
    rumor_output, pred_edges = model(data)
    
    print("  2. è®¡ç®—æŸå¤±")
    # é“¾æ¥é¢„æµ‹æŸå¤± (äºŒåˆ†ç±»)
    link_target = torch.tensor([1.0])  # å‡è®¾Dâ†’Eç¡®å®å‘ç”Ÿäº†
    link_loss = F.binary_cross_entropy(pred_edges, link_target)
    
    # è°£è¨€æ£€æµ‹æŸå¤± (å¤šåˆ†ç±»)  
    rumor_loss = F.nll_loss(rumor_output, data.label)
    
    # æ€»æŸå¤±
    total_loss = 0.4 * link_loss + 0.6 * rumor_loss
    
    print(f"    ğŸ”— é“¾æ¥é¢„æµ‹æŸå¤±: {link_loss.item():.4f}")
    print(f"    ğŸ•µï¸ è°£è¨€æ£€æµ‹æŸå¤±: {rumor_loss.item():.4f}")  
    print(f"    ğŸ“Š æ€»æŸå¤±: {total_loss.item():.4f}")
    
    print("  3. åå‘ä¼ æ’­")
    optimizer.zero_grad()
    total_loss.backward()
    
    print("  4. æ¢¯åº¦åˆ†æ")
    for name, param in shared_encoder.named_parameters():
        if param.grad is not None:
            print(f"    {name}: æ¢¯åº¦èŒƒæ•° = {param.grad.norm().item():.6f}")
    
    print("  5. å‚æ•°æ›´æ–°")
    optimizer.step()
    
    print("  âœ… è®­ç»ƒæ­¥éª¤å®Œæˆï¼SharedEncoderå‚æ•°å·²æ›´æ–°ï¼Œå½±å“ä¸¤ä¸ªä»»åŠ¡ã€‚")

if __name__ == "__main__":
    demonstrate_forward_pass()
    explain_shared_encoder_role()
    demonstrate_training_step()
